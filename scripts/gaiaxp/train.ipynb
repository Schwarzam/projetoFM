{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dc8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdc1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767477ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astromodal.config import load_config\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import random\n",
    "from pathlib import Path\n",
    "from astromodal.datasets.datacubes import load_datacube_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a723eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"/home/schwarz/projetoFM/config.yaml\")\n",
    "\n",
    "hdd_folder = config['hdd_folder']\n",
    "\n",
    "hddfolder = Path(config[\"hdd_folder\"]) / \"image_latents\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bff0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = config['datacubes_paths'].replace('*', 'STRIPE82-0002')\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "header = pl.read_parquet(file, n_rows=0)\n",
    "columns = [col for col in header.columns if 'gaiaxp' in col] + [\"id\", \"mag_psf_r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd01620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] - Found 2444 datacube files\n",
      "[info] - Subsampled to 500 files\n",
      "[info] - Training files: 450\n",
      "[info] - Validation files: 50\n"
     ]
    }
   ],
   "source": [
    "train_files, val_files = load_datacube_files(config['datacubes_paths'], train_val_split=0.9, nfiles_subsample=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7547cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train files:   0%|          | 0/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train files: 100%|██████████| 450/450 [01:26<00:00,  5.21it/s]\n",
      "Loading val files: 100%|██████████| 50/50 [00:10<00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = None\n",
    "\n",
    "for f in tqdm(train_files, desc=\"Loading train files\"):\n",
    "    try:\n",
    "        df = pl.read_parquet(f, columns=columns, use_pyarrow=True)\n",
    "        df = df.filter(pl.col(columns[0]).is_not_null())\n",
    "        \n",
    "        df = df.filter(pl.col(\"mag_psf_r\") < 21)\n",
    "        \n",
    "        \n",
    "        if df.height == 0:\n",
    "            continue\n",
    "\n",
    "        train_df = df if train_df is None else pl.concat([train_df, df], how=\"vertical\", rechunk=False)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "val_df = None\n",
    "\n",
    "for f in tqdm(val_files, desc=\"Loading val files\"):\n",
    "    try:\n",
    "        df = pl.read_parquet(f, columns=columns, use_pyarrow=True)\n",
    "        df = df.filter(pl.col(columns[0]).is_not_null())\n",
    "        \n",
    "        df = df.filter(pl.col(\"mag_psf_r\") < 21)\n",
    "        \n",
    "        \n",
    "        if df.height == 0:\n",
    "            continue\n",
    "\n",
    "        val_df = df if val_df is None else pl.concat([val_df, df], how=\"vertical\", rechunk=False)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8147b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f08841",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.filter(pl.col(\"gaiaxp_solution_id\").is_not_null())\n",
    "val_df = val_df.filter(pl.col(\"gaiaxp_solution_id\").is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9fd65af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184987, 25358)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "908993dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns, remove prefix gaiaxp_\n",
    "train_df = train_df.rename(lambda x: x.replace('gaiaxp_', ''))\n",
    "val_df = val_df.rename(lambda x: x.replace('gaiaxp_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167a1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "train_df = train_df.with_columns(\n",
    "    pl.col(\"bp_coefficients\")\n",
    "      .map_elements(ast.literal_eval, return_dtype=pl.List(pl.Float64))\n",
    ")\n",
    "\n",
    "train_df = train_df.with_columns(\n",
    "    pl.col(\"rp_coefficients\")\n",
    "      .map_elements(ast.literal_eval, return_dtype=pl.List(pl.Float64))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68fa513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astromodal.specifics.gaiaxp_scaler import fit_standard_scaler_vec_from_gaiaxp\n",
    "\n",
    "scaler_bp = fit_standard_scaler_vec_from_gaiaxp(\n",
    "    train_df,\n",
    "    col=\"bp_coefficients\",\n",
    "    max_rows=100000,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "scaler_rp = fit_standard_scaler_vec_from_gaiaxp(\n",
    "    train_df,\n",
    "    col=\"rp_coefficients\",\n",
    "    max_rows=100000,\n",
    "    seed=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3448d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_bp.save(Path(config[\"models_folder\"]) / \"scalers\" / \"gaiaxp_scaler_bp.pkl\")\n",
    "scaler_rp.save(Path(config[\"models_folder\"]) / \"scalers\" / \"gaiaxp_scaler_rp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e052780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def _parse_list_cell(x):\n",
    "    # Handles: list/np.ndarray OR string like \"[1,2,3]\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        return np.asarray(x, dtype=np.float32)\n",
    "    if isinstance(x, str):\n",
    "        # safe parse\n",
    "        return np.asarray(ast.literal_eval(x), dtype=np.float32)\n",
    "    # fallback\n",
    "    return np.asarray(x, dtype=np.float32)\n",
    "\n",
    "def df_col_to_matrix(df, col=\"bp_coefficients\"):\n",
    "    arr = []\n",
    "    for x in df[col].to_list():\n",
    "        v = _parse_list_cell(x)\n",
    "        if v is None:\n",
    "            continue\n",
    "        arr.append(v)\n",
    "    if len(arr) == 0:\n",
    "        raise ValueError(f\"No valid rows found in {col}\")\n",
    "    # all should have same length\n",
    "    D = len(arr[0])\n",
    "    bad = [i for i,a in enumerate(arr) if len(a) != D]\n",
    "    if bad:\n",
    "        raise ValueError(f\"Inconsistent coefficient lengths. Example bad idx: {bad[:5]}\")\n",
    "    return np.stack(arr, axis=0).astype(np.float32)  # [N, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70efd76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 000 | train_loss(norm)=0.303548 | val_mse=714.362 rmse=26.7275 nrmse_p90=7.768789349716187 | rmse_idx(mean/med/max)=6.966/0.5249/143.6 | best_mse=714.362 @ 0 | bad_epochs=0/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 001 | train_loss(norm)=0.118965 | val_mse=94.7076 rmse=9.73178 nrmse_p90=2.8286981819200445 | rmse_idx(mean/med/max)=2.473/0.2408/64.73 | best_mse=94.7076 @ 1 | bad_epochs=0/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 002 | train_loss(norm)=0.060663 | val_mse=72.607 rmse=8.52097 nrmse_p90=2.4767570575025246 | rmse_idx(mean/med/max)=2.358/0.1936/48.49 | best_mse=72.607 @ 2 | bad_epochs=0/8\n",
      "Epoch 003 | train_loss(norm)=0.0272439 | val_mse=86.8943 rmse=9.32171 nrmse_p90=2.7095049526134956 | rmse_idx(mean/med/max)=2.033/0.1435/66.79 | best_mse=72.607 @ 2 | bad_epochs=1/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 004 | train_loss(norm)=0.0139259 | val_mse=22.4634 rmse=4.73956 nrmse_p90=1.3776279206128328 | rmse_idx(mean/med/max)=1.236/0.074/28.29 | best_mse=22.4634 @ 4 | bad_epochs=0/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 005 | train_loss(norm)=0.00749209 | val_mse=6.75049 rmse=2.59817 nrmse_p90=0.7551999080332671 | rmse_idx(mean/med/max)=0.765/0.04731/13.72 | best_mse=6.75049 @ 5 | bad_epochs=0/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 006 | train_loss(norm)=0.0045318 | val_mse=4.82593 rmse=2.1968 nrmse_p90=0.6385348603542472 | rmse_idx(mean/med/max)=0.6302/0.08634/12.1 | best_mse=4.82593 @ 6 | bad_epochs=0/8\n",
      "Epoch 007 | train_loss(norm)=0.00212886 | val_mse=8.79425 rmse=2.96551 nrmse_p90=0.861972988623285 | rmse_idx(mean/med/max)=0.7739/0.04986/17.79 | best_mse=4.82593 @ 6 | bad_epochs=1/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 008 | train_loss(norm)=0.00211888 | val_mse=1.988 rmse=1.40997 nrmse_p90=0.4098290336899041 | rmse_idx(mean/med/max)=0.4218/0.05906/7.497 | best_mse=1.988 @ 8 | bad_epochs=0/8\n",
      "Epoch 009 | train_loss(norm)=0.00550053 | val_mse=34.7801 rmse=5.89746 nrmse_p90=1.7141921822828043 | rmse_idx(mean/med/max)=1.101/0.02377/42.6 | best_mse=1.988 @ 8 | bad_epochs=1/8\n",
      "Epoch 010 | train_loss(norm)=0.00183731 | val_mse=38.1739 rmse=6.1785 nrmse_p90=1.7958800936091652 | rmse_idx(mean/med/max)=1.112/0.0397/45.12 | best_mse=1.988 @ 8 | bad_epochs=2/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 011 | train_loss(norm)=0.00163367 | val_mse=0.538483 rmse=0.733814 nrmse_p90=0.2132948800469522 | rmse_idx(mean/med/max)=0.2334/0.02381/4.086 | best_mse=0.538483 @ 11 | bad_epochs=0/8\n",
      "Epoch 012 | train_loss(norm)=0.00122931 | val_mse=8.92732 rmse=2.98786 nrmse_p90=0.8684701938845776 | rmse_idx(mean/med/max)=0.7359/0.01743/19.36 | best_mse=0.538483 @ 11 | bad_epochs=1/8\n",
      "Epoch 013 | train_loss(norm)=0.000713137 | val_mse=8.84248 rmse=2.97363 nrmse_p90=0.8643333265224983 | rmse_idx(mean/med/max)=0.6025/0.01486/20.69 | best_mse=0.538483 @ 11 | bad_epochs=2/8\n",
      "Epoch 014 | train_loss(norm)=0.0005545 | val_mse=1.08747 rmse=1.04282 nrmse_p90=0.3031114780585958 | rmse_idx(mean/med/max)=0.2851/0.01806/6.154 | best_mse=0.538483 @ 11 | bad_epochs=3/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 015 | train_loss(norm)=0.000734409 | val_mse=0.318291 rmse=0.564173 nrmse_p90=0.16398594025209362 | rmse_idx(mean/med/max)=0.1859/0.01186/3.105 | best_mse=0.318291 @ 15 | bad_epochs=0/8\n",
      "Epoch 016 | train_loss(norm)=0.000502156 | val_mse=1.14731 rmse=1.07113 nrmse_p90=0.31134041494265724 | rmse_idx(mean/med/max)=0.2953/0.01205/5.996 | best_mse=0.318291 @ 15 | bad_epochs=1/8\n",
      "[info] - Saved SpectralPatchRVQ to /home/schwarz/projetoFM/outputs/tokenizers/gaiaxp_spectral_rvq_bp.pt\n",
      "Epoch 017 | train_loss(norm)=0.000437908 | val_mse=0.0430737 rmse=0.207542 nrmse_p90=0.06032540963672331 | rmse_idx(mean/med/max)=0.07417/0.01312/1.188 | best_mse=0.0430737 @ 17 | bad_epochs=0/8\n",
      "Epoch 018 | train_loss(norm)=0.000245062 | val_mse=0.197228 rmse=0.444104 nrmse_p90=0.12908580773404546 | rmse_idx(mean/med/max)=0.1131/0.0117/3.027 | best_mse=0.0430737 @ 17 | bad_epochs=1/8\n",
      "Epoch 019 | train_loss(norm)=0.000261061 | val_mse=1.48368 rmse=1.21807 nrmse_p90=0.3540502934490915 | rmse_idx(mean/med/max)=0.2996/0.007943/7.837 | best_mse=0.0430737 @ 17 | bad_epochs=2/8\n",
      "Epoch 020 | train_loss(norm)=9.67549e-05 | val_mse=3.91986 rmse=1.97986 nrmse_p90=0.5754792706910122 | rmse_idx(mean/med/max)=0.3199/0.008259/14.57 | best_mse=0.0430737 @ 17 | bad_epochs=3/8\n",
      "Epoch 021 | train_loss(norm)=9.06648e-05 | val_mse=1.05238 rmse=1.02586 nrmse_p90=0.29818203710494945 | rmse_idx(mean/med/max)=0.2271/0.008545/6.615 | best_mse=0.0430737 @ 17 | bad_epochs=4/8\n",
      "Epoch 022 | train_loss(norm)=0.000179862 | val_mse=6.35292 rmse=2.5205 nrmse_p90=0.7326238595966633 | rmse_idx(mean/med/max)=0.4539/0.00783/18.16 | best_mse=0.0430737 @ 17 | bad_epochs=5/8\n",
      "Epoch 023 | train_loss(norm)=0.000178876 | val_mse=3.98638 rmse=1.99659 nrmse_p90=0.5803415324023398 | rmse_idx(mean/med/max)=0.3336/0.004993/14.69 | best_mse=0.0430737 @ 17 | bad_epochs=6/8\n",
      "Epoch 024 | train_loss(norm)=3.47022e-05 | val_mse=20.0389 rmse=4.47648 nrmse_p90=1.3011617535390674 | rmse_idx(mean/med/max)=0.749/0.00442/32.28 | best_mse=0.0430737 @ 17 | bad_epochs=7/8\n",
      "Epoch 025 | train_loss(norm)=3.52093e-05 | val_mse=0.827136 rmse=0.90947 nrmse_p90=0.2643521006163985 | rmse_idx(mean/med/max)=0.1563/0.004856/6.712 | best_mse=0.0430737 @ 17 | bad_epochs=8/8\n",
      "\n",
      "✔ Early stopping at epoch 25 (best @ 17, mse=0.0430737)\n",
      "\n",
      "✔ Best model saved at epoch 17 with val_mse=0.0430737\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pathlib import Path\n",
    "\n",
    "from astromodal.tokenizers.rvq import ResidualVQ\n",
    "from astromodal.tokenizers.spectralrvq import SpectralPatchRVQ\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# helpers: weights\n",
    "# -------------------------\n",
    "\n",
    "def compute_coeff_weights_from_train(\n",
    "    train_df,\n",
    "    *,\n",
    "    col=\"bp_coefficients\",\n",
    "    method=\"inv_p90\",   # \"inv_p90\" | \"inv_std\" | \"none\"\n",
    "    eps=1e-3,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns weight vector w: [55] in original units space, normalized to mean=1.\n",
    "    Used to weight per-position MSE (L dimension).\n",
    "    \"\"\"\n",
    "    X = df_col_to_matrix(train_df, col=col).astype(np.float64)  # [N,55]\n",
    "\n",
    "    if method == \"none\":\n",
    "        w = np.ones(X.shape[1], dtype=np.float64)\n",
    "\n",
    "    elif method == \"inv_p90\":\n",
    "        p90 = np.quantile(np.abs(X), 0.90, axis=0)  # [55]\n",
    "        w = 1.0 / np.clip(p90, eps, None)\n",
    "\n",
    "    elif method == \"inv_std\":\n",
    "        std = np.std(X, axis=0)  # [55]\n",
    "        w = 1.0 / np.clip(std, eps, None)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method={method}\")\n",
    "\n",
    "    w = w / np.mean(w)\n",
    "    return w.astype(np.float32)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# DataLoader that also provides w: [B,55]\n",
    "# -------------------------\n",
    "\n",
    "def make_coeff_loader(\n",
    "    df,\n",
    "    scaler,\n",
    "    *,\n",
    "    col=\"bp_coefficients\",\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    weight_vec: np.ndarray | None = None,   # [55] or None\n",
    "):\n",
    "    # raw: [N,55]\n",
    "    X = df_col_to_matrix(df, col=col).astype(\"float32\")\n",
    "\n",
    "    # normalize in same shape [N,55]\n",
    "    Xn = scaler.transform_x(X).astype(\"float32\")\n",
    "\n",
    "    # enforce sequence layout [N,55,1]\n",
    "    Xn = Xn.reshape(Xn.shape[0], Xn.shape[1], 1)\n",
    "    assert Xn.ndim == 3 and Xn.shape[1] == 55 and Xn.shape[2] == 1, f\"bad Xn shape {Xn.shape}\"\n",
    "\n",
    "    ds = TensorDataset(torch.from_numpy(Xn))\n",
    "\n",
    "    # custom collate to attach per-position weights\n",
    "    w_t = None\n",
    "    if weight_vec is not None:\n",
    "        w_t = torch.as_tensor(weight_vec, dtype=torch.float32)  # [55]\n",
    "\n",
    "    def collate(batch):\n",
    "        # batch is list of tuples: [(x,), (x,), ...]\n",
    "        x = torch.stack([b[0] for b in batch], dim=0)  # [B,55,1]\n",
    "        if w_t is None:\n",
    "            return (x,)  # old behavior\n",
    "        B = x.shape[0]\n",
    "        w = w_t.unsqueeze(0).expand(B, -1).contiguous()  # [B,55]\n",
    "        # SpectralPatchRVQ.train_epoch expects (x, mask?, w?)\n",
    "        return (x, None, w)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate,\n",
    "    )\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# eval in ORIGINAL units + per-index metrics\n",
    "# -------------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_tok_unscaled_stats(\n",
    "    tok: SpectralPatchRVQ,\n",
    "    dl,\n",
    "    scaler,\n",
    "    device=\"cuda\",\n",
    "    p90_ref: float | None = None,  # optional: global p90(|coeff|) for NRMSE\n",
    "):\n",
    "    tok.eval()\n",
    "\n",
    "    sum_mse = 0.0\n",
    "    n = 0\n",
    "\n",
    "    sum_diff2_i = None  # [55]\n",
    "    count_i = 0\n",
    "\n",
    "    for batch in dl:\n",
    "        # batch can be (x,) or (x, None, w)\n",
    "        x_norm = batch[0].to(device=device, dtype=torch.float32, non_blocking=True)  # [B,55,1]\n",
    "\n",
    "        out = tok.encode(x_norm, update_ema=False)\n",
    "        xq_norm = out[\"x_q\"]  # [B,55,1]\n",
    "\n",
    "        # inverse transform expects [B,55] (safer)\n",
    "        x_raw  = scaler.inverse_transform_x(x_norm.detach().cpu().numpy().squeeze(-1))   # [B,55]\n",
    "        xq_raw = scaler.inverse_transform_x(xq_norm.detach().cpu().numpy().squeeze(-1))  # [B,55]\n",
    "\n",
    "        diff2 = (xq_raw - x_raw) ** 2  # [B,55]\n",
    "\n",
    "        mse_global = float(diff2.mean())\n",
    "        sum_mse += mse_global * x_norm.shape[0]\n",
    "        n += x_norm.shape[0]\n",
    "\n",
    "        s = diff2.sum(axis=0)  # [55]\n",
    "        sum_diff2_i = s if sum_diff2_i is None else (sum_diff2_i + s)\n",
    "        count_i += diff2.shape[0]\n",
    "\n",
    "    mse = sum_mse / max(n, 1)\n",
    "    rmse = float(np.sqrt(mse))\n",
    "\n",
    "    mse_i = sum_diff2_i / max(count_i, 1)  # [55]\n",
    "    rmse_i = np.sqrt(mse_i)\n",
    "\n",
    "    # NRMSE using provided p90 reference (recommended)\n",
    "    nrmse_p90 = None\n",
    "    if p90_ref is not None:\n",
    "        nrmse_p90 = float(rmse / max(float(p90_ref), 1e-12))\n",
    "\n",
    "    return {\n",
    "        \"mse\": float(mse),\n",
    "        \"rmse\": float(rmse),\n",
    "        \"mse_x_1e6\": float(mse * 1e6),\n",
    "        \"-log10(mse)\": float(-np.log10(mse + 1e-300)),\n",
    "        \"rmse_idx_mean\": float(np.mean(rmse_i)),\n",
    "        \"rmse_idx_median\": float(np.median(rmse_i)),\n",
    "        \"rmse_idx_max\": float(np.max(rmse_i)),\n",
    "        \"rmse_idx_min\": float(np.min(rmse_i)),\n",
    "        \"nrmse_p90\": nrmse_p90,\n",
    "        # if you want to plot later:\n",
    "        \"rmse_i\": rmse_i,\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# training\n",
    "# -------------------------\n",
    "\n",
    "def train_coeff_spectralrvq(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    scaler,\n",
    "    *,\n",
    "    col=\"bp_coefficients\",\n",
    "    codebook_size=1024,\n",
    "    num_stages=4,\n",
    "    decay=0.99,\n",
    "    epochs=60,\n",
    "    batch_size=1024,\n",
    "    device=\"cuda\",\n",
    "    save_path=\"best_spectralrvq.pt\",\n",
    "    weight_method=\"inv_p90\",   # \"inv_p90\" | \"inv_std\" | \"none\"\n",
    "    patience=8,                # <--- NEW: early stopping patience\n",
    "    min_delta=0.0,             # <--- NEW: require improvement > min_delta\n",
    "):\n",
    "    # weights in ORIGINAL space (per index)\n",
    "    w_vec = compute_coeff_weights_from_train(\n",
    "        train_df, col=col, method=weight_method\n",
    "    ) if weight_method != \"none\" else None\n",
    "\n",
    "    # p90 reference for NRMSE (global, original units)\n",
    "    Xv = df_col_to_matrix(val_df, col=col).astype(np.float64)\n",
    "    p90_ref = float(np.quantile(np.abs(Xv), 0.90))\n",
    "\n",
    "    dl_train = make_coeff_loader(\n",
    "        train_df, scaler,\n",
    "        col=col, batch_size=batch_size, shuffle=True,\n",
    "        weight_vec=w_vec\n",
    "    )\n",
    "    dl_val = make_coeff_loader(\n",
    "        val_df, scaler,\n",
    "        col=col, batch_size=batch_size, shuffle=False,\n",
    "        weight_vec=None\n",
    "    )\n",
    "\n",
    "    # 55 tokens -> patch_size=1, channels=1 -> RVQ dim=1\n",
    "    P = 1\n",
    "    C = 1\n",
    "    rvq = ResidualVQ(\n",
    "        dim=P * C,\n",
    "        num_stages=num_stages,\n",
    "        codebook_size=codebook_size,\n",
    "        decay=decay,\n",
    "    ).to(device)\n",
    "\n",
    "    tok = SpectralPatchRVQ(\n",
    "        rvq=rvq,\n",
    "        patch_size=P,\n",
    "        channels=C,\n",
    "    ).to(device)\n",
    "\n",
    "    history = []\n",
    "    best_mse = float(\"inf\")\n",
    "    best_epoch = -1\n",
    "    bad_epochs = 0\n",
    "\n",
    "    tok.train()\n",
    "    for epoch in range(epochs):\n",
    "        # IMPORTANT: EMA must stay ON; otherwise RVQ stops learning.\n",
    "        train_stats = tok.train_epoch(\n",
    "            dl_train, device=device, update_ema=True\n",
    "        )\n",
    "\n",
    "        val_stats = eval_tok_unscaled_stats(\n",
    "            tok, dl_val, scaler, device=device, p90_ref=p90_ref\n",
    "        )\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": int(epoch),\n",
    "            \"train_loss_norm\": float(train_stats[\"loss\"]),\n",
    "            \"weight_method\": str(weight_method),\n",
    "            **{k: v for k, v in val_stats.items() if k != \"rmse_i\"},\n",
    "        })\n",
    "\n",
    "        # -------- best checkpoint + early stopping --------\n",
    "        improved = (val_stats[\"mse\"] < (best_mse - float(min_delta)))\n",
    "\n",
    "        if improved:\n",
    "            best_mse = float(val_stats[\"mse\"])\n",
    "            best_epoch = int(epoch)\n",
    "            bad_epochs = 0\n",
    "\n",
    "            tok.save(\n",
    "                str(save_path),\n",
    "                additional_info={\n",
    "                    \"best_epoch\": best_epoch,\n",
    "                    \"best_val_mse\": best_mse,\n",
    "                    \"codebook_size\": int(codebook_size),\n",
    "                    \"num_stages\": int(num_stages),\n",
    "                    \"decay\": float(decay),\n",
    "                    \"col\": str(col),\n",
    "                    \"weight_method\": str(weight_method),\n",
    "                    \"p90_ref\": float(p90_ref),\n",
    "                },\n",
    "            )\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | \"\n",
    "            f\"train_loss(norm)={train_stats['loss']:.6g} | \"\n",
    "            f\"val_mse={val_stats['mse']:.6g} rmse={val_stats['rmse']:.6g} \"\n",
    "            f\"nrmse_p90={val_stats['nrmse_p90'] if val_stats['nrmse_p90'] is not None else None} | \"\n",
    "            f\"rmse_idx(mean/med/max)={val_stats['rmse_idx_mean']:.4g}/\"\n",
    "            f\"{val_stats['rmse_idx_median']:.4g}/\"\n",
    "            f\"{val_stats['rmse_idx_max']:.4g} | \"\n",
    "            f\"best_mse={best_mse:.6g} @ {best_epoch} | \"\n",
    "            f\"bad_epochs={bad_epochs}/{patience}\"\n",
    "        )\n",
    "\n",
    "        if bad_epochs >= int(patience):\n",
    "            print(f\"\\n✔ Early stopping at epoch {epoch} (best @ {best_epoch}, mse={best_mse:.6g})\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\n✔ Best model saved at epoch {best_epoch} with val_mse={best_mse:.6g}\")\n",
    "    return tok, history\n",
    "\n",
    "# -------------------------\n",
    "# example\n",
    "# -------------------------\n",
    "\n",
    "filt = \"bp\"\n",
    "scaler = scaler_bp\n",
    "\n",
    "tok, hist = train_coeff_spectralrvq(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    scaler,\n",
    "    col=f\"{filt}_coefficients\",\n",
    "    codebook_size=1024,\n",
    "    num_stages=3,\n",
    "    epochs=40,\n",
    "    save_path=Path(config[\"models_folder\"]) / \"tokenizers\" / f\"gaiaxp_spectral_rvq_{filt}.pt\",\n",
    "    weight_method=\"inv_p90\",\n",
    "    patience=8,\n",
    "    min_delta=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b25451c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median |coeff|: 0.2966558188199997\n",
      "p90 |coeff|: 3.440374636650086\n"
     ]
    }
   ],
   "source": [
    "X = df_col_to_matrix(val_df, col=\"bp_coefficients\").astype(np.float64)\n",
    "print(\"median |coeff|:\", np.median(np.abs(X)))\n",
    "print(\"p90 |coeff|:\", np.quantile(np.abs(X), 0.90))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
