{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dc8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "767477ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astromodal.config import load_config\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca31f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/astrodados4/downloads/hypercube/datacube_*.parquet\n"
     ]
    }
   ],
   "source": [
    "config = load_config(\"/home/schwarz/projetoFM/config.yaml\")\n",
    "\n",
    "print(config['datacubes_paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c7f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube_paths = config['datacubes_paths']\n",
    "\n",
    "from astromodal.datasets.datacubes import load_datacube_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4347d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] - Found 2444 datacube files\n",
      "[info] - Subsampled to 1 files\n",
      "[info] - Training files: 1\n",
      "[info] - Validation files: 0\n"
     ]
    }
   ],
   "source": [
    "train_files, val_files = load_datacube_files(\n",
    "    datacubes_paths = datacube_paths,\n",
    "    train_val_split = 1,\n",
    "    nfiles_subsample = 1,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf07eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"splus_cut_F378\",\n",
    "    \"splus_cut_F395\",\n",
    "    \"splus_cut_F410\",\n",
    "    \"splus_cut_F430\",\n",
    "    \"splus_cut_F515\",\n",
    "    \"splus_cut_F660\",\n",
    "    \"splus_cut_F861\",\n",
    "    \"splus_cut_R\",\n",
    "    \"splus_cut_I\",\n",
    "    \"splus_cut_Z\",\n",
    "    \"splus_cut_U\",\n",
    "    \"splus_cut_G\",\n",
    "]\n",
    "\n",
    "bands = [\"F378\", \"F395\", \"F410\", \"F430\", \"F515\", \"F660\", \"F861\", \"R\", \"I\", \"Z\", \"U\", \"G\"]\n",
    "cutout_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd199002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.26s/it]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_df = None\n",
    "\n",
    "for f in tqdm(train_files, desc=\"Loading train files\"):\n",
    "    df = pl.read_parquet(f, columns=columns, use_pyarrow=True)\n",
    "    df = df.filter(pl.col(columns[0]).is_not_null())\n",
    "\n",
    "    if df.height == 0:\n",
    "        continue\n",
    "\n",
    "    train_df = df if train_df is None else pl.concat([train_df, df], how=\"vertical\", rechunk=False)\n",
    "\n",
    "train_df = train_df.rechunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f262f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val files: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'rechunk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     13\u001b[39m     val_df = df \u001b[38;5;28;01mif\u001b[39;00m val_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pl.concat([val_df, df], how=\u001b[33m\"\u001b[39m\u001b[33mvertical\u001b[39m\u001b[33m\"\u001b[39m, rechunk=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m val_df = \u001b[43mval_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrechunk\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'rechunk'"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "val_df = None\n",
    "\n",
    "for f in tqdm(val_files, desc=\"Loading val files\"):\n",
    "    df = pl.read_parquet(f, columns=columns, use_pyarrow=True)\n",
    "    df = df.filter(pl.col(columns[0]).is_not_null())\n",
    "\n",
    "    if df.height == 0:\n",
    "        continue\n",
    "\n",
    "    val_df = df if val_df is None else pl.concat([val_df, df], how=\"vertical\", rechunk=False)\n",
    "\n",
    "val_df = val_df.rechunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53db5fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mastromodal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspluscuts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SplusCutoutsDataset\n\u001b[32m      3\u001b[39m train_dataset = SplusCutoutsDataset(\n\u001b[32m      4\u001b[39m     train_df,\n\u001b[32m      5\u001b[39m     bands=bands,\n\u001b[32m      6\u001b[39m     img_size=cutout_size,\n\u001b[32m      7\u001b[39m     return_valid_mask=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m val_dataset = \u001b[43mSplusCutoutsDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutout_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_valid_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projetoFM/astromodal/datasets/spluscuts.py:131\u001b[39m, in \u001b[36mSplusCutoutsDataset.__init__\u001b[39m\u001b[34m(self, df, bands, img_size, return_valid_mask, eps, min_valid, mad_mult)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28mself\u001b[39m.min_valid = min_valid\n\u001b[32m    129\u001b[39m \u001b[38;5;28mself\u001b[39m.mad_mult = mad_mult\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28mself\u001b[39m._len = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheight\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# Optional sanity check (fast): ensure columns exist\u001b[39;00m\n\u001b[32m    134\u001b[39m missing = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msplus_cut_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bands \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msplus_cut_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns]\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'height'"
     ]
    }
   ],
   "source": [
    "from astromodal.datasets.spluscuts import SplusCutoutsDataset\n",
    "\n",
    "train_dataset = SplusCutoutsDataset(\n",
    "    train_df,\n",
    "    bands=bands,\n",
    "    img_size=cutout_size,\n",
    "    return_valid_mask=True,\n",
    ")\n",
    "val_dataset = SplusCutoutsDataset(\n",
    "    val_df,\n",
    "    bands=bands,\n",
    "    img_size=cutout_size,\n",
    "    return_valid_mask=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcbec487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import logpool\n",
    "\n",
    "def train_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    optimizer,\n",
    "    device,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for x_norm, m_valid in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        x_norm = x_norm.to(device, non_blocking=True).float()\n",
    "        m_valid = m_valid.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        x_recon, _ = model(x_norm)\n",
    "\n",
    "        mv = m_valid > 0.5\n",
    "        if mv.any():\n",
    "            loss = F.mse_loss(x_recon[mv], x_norm[mv])\n",
    "        else:\n",
    "            loss = x_recon.sum() * 0.0\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / max(n_batches, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for x_norm, m_valid in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
    "        x_norm = x_norm.to(device, non_blocking=True).float()\n",
    "        m_valid = m_valid.to(device, non_blocking=True)\n",
    "\n",
    "        x_recon, _ = model(x_norm)\n",
    "\n",
    "        mv = m_valid > 0.5\n",
    "        if mv.any():\n",
    "            loss = F.mse_loss(x_recon[mv], x_norm[mv])\n",
    "        else:\n",
    "            loss = x_recon.sum() * 0.0\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / max(n_batches, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8bf7050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "batch_size = 1024\n",
    "max_gpu_batch_size = 1024\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "latent_dim = 2\n",
    "\n",
    "model_output_path = Path(config['models_folder']) / \"./autoencoder_model_silu.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f70b5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from astromodal.models.autoencoder import AutoEncoder\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=max_gpu_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62d6bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(\n",
    "    in_channels = len(bands),\n",
    "    latent_dim = latent_dim,\n",
    "    use_skips=False\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77cc778045f4d94a9b7196f4f8f808d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/454 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logpool\n",
    "import torch\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "history = {\n",
    "    \"epoch\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    history[\"epoch\"].append(epoch)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    logpool.info(\n",
    "        f\"Epoch {epoch:03d}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\"\n",
    "    )\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"history\": history,   # ðŸ‘ˆ saved here\n",
    "                \"config\": {\n",
    "                    \"in_channels\": len(bands),\n",
    "                    \"out_channels\": len(bands),\n",
    "                    \"latent_dim\": latent_dim,\n",
    "                },\n",
    "            },\n",
    "            model_output_path,\n",
    "        )\n",
    "        logpool.info(f\"  âœ“ Saved best model (val_loss: {val_loss:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c798532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from astromodal.models.autoencoder import AutoEncoder\n",
    "\n",
    "def load_autoencoder(ckpt_path: str, device: torch.device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    # Try to recover config from checkpoint; fallback to your known values\n",
    "    in_channels = len(bands)\n",
    "    latent_dim = 2\n",
    "\n",
    "    model = AutoEncoder(\n",
    "        in_channels=in_channels,\n",
    "        latent_dim=latent_dim,\n",
    "    ).to(device)\n",
    "\n",
    "    # support both raw state_dict or wrapped checkpoint\n",
    "    state = ckpt[\"model_state_dict\"] if \"model_state_dict\" in ckpt else ckpt\n",
    "    model.load_state_dict(state, strict=True)\n",
    "\n",
    "    model.eval()\n",
    "    return model, ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a1a5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, ckpt = load_autoencoder(model_output_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c60bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def percentile_stretch(img2d: np.ndarray, p_lo=1, p_hi=99):\n",
    "    finite = np.isfinite(img2d)\n",
    "    if not finite.any():\n",
    "        return img2d, 0.0, 1.0\n",
    "    vmin = np.percentile(img2d[finite], p_lo)\n",
    "    vmax = np.percentile(img2d[finite], p_hi)\n",
    "    if vmax <= vmin:\n",
    "        vmax = vmin + 1e-6\n",
    "    out = np.clip((img2d - vmin) / (vmax - vmin), 0, 1)\n",
    "    return out, vmin, vmax\n",
    "\n",
    "def symmetric_residual_stretch(res2d: np.ndarray, p_hi=99):\n",
    "    \"\"\"\n",
    "    Map residuals to [0,1] using symmetric limits [-v, +v],\n",
    "    where v = percentile(|res|, p_hi).\n",
    "    Zero residual -> 0.5.\n",
    "    \"\"\"\n",
    "    finite = np.isfinite(res2d)\n",
    "    if not finite.any():\n",
    "        v = 1.0\n",
    "        out = np.zeros_like(res2d) + 0.5\n",
    "        return out, -v, v\n",
    "\n",
    "    absvals = np.abs(res2d[finite])\n",
    "    v = np.percentile(absvals, p_hi)\n",
    "    if v <= 0:\n",
    "        v = 1e-6\n",
    "\n",
    "    out = np.clip((res2d + v) / (2 * v), 0, 1)\n",
    "    return out, -v, v\n",
    "\n",
    "def plot_before_after_residual_12bands(\n",
    "    x_in: torch.Tensor,        # (C,H,W)\n",
    "    x_rec: torch.Tensor,       # (C,H,W)\n",
    "    band_names=None,\n",
    "    p_lo=1,\n",
    "    p_hi=99,\n",
    "    use_input_percentiles=True,\n",
    "    residual_p_hi=99,\n",
    "    suptitle=None,\n",
    "):\n",
    "    x_in = x_in.detach().float().cpu().numpy()\n",
    "    x_rec = x_rec.detach().float().cpu().numpy()\n",
    "    res = x_rec - x_in\n",
    "\n",
    "    C, H, W = x_in.shape\n",
    "    assert C == 12, f\"Expected 12 bands, got {C}\"\n",
    "\n",
    "    if band_names is None:\n",
    "        band_names = [f\"b{i}\" for i in range(C)]\n",
    "\n",
    "    fig, axes = plt.subplots(3, C, figsize=(2.2*C, 6.6), constrained_layout=True)\n",
    "\n",
    "    for c in range(C):\n",
    "        # same scaling for input & recon\n",
    "        ref = x_in[c] if use_input_percentiles else np.concatenate([x_in[c].ravel(), x_rec[c].ravel()])\n",
    "        _, vmin, vmax = percentile_stretch(ref, p_lo, p_hi)\n",
    "\n",
    "        def norm_with(v):\n",
    "            if vmax <= vmin:\n",
    "                return np.zeros_like(v)\n",
    "            return np.clip((v - vmin) / (vmax - vmin), 0, 1)\n",
    "\n",
    "        im_in = norm_with(x_in[c])\n",
    "        im_rec = norm_with(x_rec[c])\n",
    "\n",
    "        # residual scaling: symmetric around 0\n",
    "        im_res, rmin, rmax = symmetric_residual_stretch(res[c], p_hi=residual_p_hi)\n",
    "\n",
    "        axes[0, c].imshow(im_in, origin=\"lower\")\n",
    "        axes[0, c].set_title(str(band_names[c]))\n",
    "        axes[1, c].imshow(im_rec, origin=\"lower\")\n",
    "        axes[2, c].imshow(im_res, origin=\"lower\")\n",
    "\n",
    "        axes[0, c].axis(\"off\")\n",
    "        axes[1, c].axis(\"off\")\n",
    "        axes[2, c].axis(\"off\")\n",
    "\n",
    "        # optional: show residual limits on bottom row\n",
    "        # axes[2, c].set_title(f\"Î” [{rmin:.2g},{rmax:.2g}]\", fontsize=8)\n",
    "\n",
    "    axes[0, 0].set_ylabel(\"Input\", fontsize=12)\n",
    "    axes[1, 0].set_ylabel(\"Recon\", fontsize=12)\n",
    "    axes[2, 0].set_ylabel(\"Residual\", fontsize=12)\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=14)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0714137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def save_reconstructions(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    band_names=None,\n",
    "    n_examples=3,\n",
    "    p_lo=1,\n",
    "    p_hi=99,\n",
    "    residual_p_hi=99,\n",
    "    output_dir=None,\n",
    "):\n",
    "    batch = next(iter(dataloader))\n",
    "    x = batch[0] if isinstance(batch, (tuple, list)) else batch\n",
    "\n",
    "    x = x.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_rec, z = model(x)\n",
    "\n",
    "    for i in range(min(n_examples, x.shape[0])):\n",
    "        fig = plot_before_after_residual_12bands(\n",
    "            x_in=x[i],\n",
    "            x_rec=x_rec[i],\n",
    "            band_names=band_names,\n",
    "            p_lo=p_lo,\n",
    "            p_hi=p_hi,\n",
    "            residual_p_hi=residual_p_hi,\n",
    "            use_input_percentiles=True,\n",
    "            suptitle=f\"Example {i} | z shape: {tuple(z.shape)}\",\n",
    "        )\n",
    "        if output_dir is not None:\n",
    "            output_path = output_dir / f\"reconstruction_{i}.png\"\n",
    "            fig.savefig(output_path)\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0141059",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "bands = [\"F378\",\"F395\",\"F410\",\"F430\",\"F515\",\"F660\",\"F861\",\"U\",\"G\",\"R\",\"I\",\"Z\"]\n",
    "\n",
    "outfolder = Path(config['models_folder']) / \"plots\" / \"autoencoder_reconstructions\"\n",
    "outfolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_reconstructions(\n",
    "    model=model,\n",
    "    dataloader=loader,\n",
    "    device=device,\n",
    "    band_names=bands,\n",
    "    n_examples=10,\n",
    "    p_lo=1,\n",
    "    p_hi=99,\n",
    "    output_dir=outfolder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f02cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
