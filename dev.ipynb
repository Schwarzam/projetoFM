{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1dc8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767477ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astromodal.config import load_config\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca31f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/astrodados4/downloads/hypercube/datacube_*.parquet\n"
     ]
    }
   ],
   "source": [
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "print(config['datacubes_paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c7f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube_paths = config['datacubes_paths']\n",
    "\n",
    "from astromodal.datasets.datacubes import load_datacube_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4347d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] - Found 2444 datacube files\n",
      "[info] - Subsampled to 10 files\n",
      "[info] - Training files: 7\n",
      "[info] - Validation files: 3\n"
     ]
    }
   ],
   "source": [
    "train_files, val_files = load_datacube_files(\n",
    "    datacubes_paths = datacube_paths,\n",
    "    train_val_split = 0.7,\n",
    "    nfiles_subsample = 10,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04d3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_random_rows_parquet(\n",
    "    path: str,\n",
    "    n_rows: int,\n",
    "    seed: int | None = None,\n",
    ") -> pl.DataFrame:\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    lf = pl.scan_parquet(path)\n",
    "\n",
    "    total = lf.select(pl.len()).collect().item()\n",
    "    if n_rows >= total:\n",
    "        return lf.collect()\n",
    "\n",
    "    # random indices\n",
    "    idx = random.sample(range(total), n_rows)\n",
    "\n",
    "    return (\n",
    "        lf\n",
    "        .with_row_count(\"_rowid\")\n",
    "        .filter(pl.col(\"_rowid\").is_in(idx))\n",
    "        .drop(\"_rowid\")\n",
    "        .collect()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf07eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"splus_cut_F378\",\n",
    "    \"splus_cut_F395\",\n",
    "    \"splus_cut_F410\",\n",
    "    \"splus_cut_F430\",\n",
    "    \"splus_cut_F515\",\n",
    "    \"splus_cut_F660\",\n",
    "    \"splus_cut_F861\",\n",
    "    \"splus_cut_R\",\n",
    "    \"splus_cut_I\",\n",
    "    \"splus_cut_Z\",\n",
    "    \"splus_cut_U\",\n",
    "    \"splus_cut_G\",\n",
    "]\n",
    "\n",
    "bands = [\"F378\", \"F395\", \"F410\", \"F430\", \"F515\", \"F660\", \"F861\", \"R\", \"I\", \"Z\", \"U\", \"G\"]\n",
    "cutout_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd199002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train files:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train files: 100%|██████████| 7/7 [01:29<00:00, 12.74s/it]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_df = None\n",
    "\n",
    "for f in tqdm(train_files, desc=\"Loading train files\"):\n",
    "    df = pl.read_parquet(f, columns=columns, use_pyarrow=True)\n",
    "    df = df.filter(pl.col(columns[0]).is_not_null())\n",
    "\n",
    "    if df.height == 0:\n",
    "        continue\n",
    "\n",
    "    train_df = df if train_df is None else pl.concat([train_df, df], how=\"vertical\", rechunk=False)\n",
    "\n",
    "train_df = train_df.rechunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f262f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading val files: 100%|██████████| 3/3 [02:11<00:00, 43.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "val_df = None\n",
    "\n",
    "for f in tqdm(val_files, desc=\"Loading val files\"):\n",
    "    df = pl.read_parquet(f, columns=columns, use_pyarrow=True)\n",
    "    df = df.filter(pl.col(columns[0]).is_not_null())\n",
    "\n",
    "    if df.height == 0:\n",
    "        continue\n",
    "\n",
    "    val_df = df if val_df is None else pl.concat([val_df, df], how=\"vertical\", rechunk=False)\n",
    "\n",
    "val_df = val_df.rechunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53db5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astromodal.datasets.spluscuts import SplusCutoutsDataset\n",
    "\n",
    "train_dataset = SplusCutoutsDataset(\n",
    "    train_df,\n",
    "    bands=bands,\n",
    "    img_size=cutout_size,\n",
    "    return_valid_mask=True,\n",
    ")\n",
    "val_dataset = SplusCutoutsDataset(\n",
    "    val_df,\n",
    "    bands=bands,\n",
    "    img_size=cutout_size,\n",
    "    return_valid_mask=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcbec487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import polars as pl\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    scaler: torch.cuda.amp.GradScaler,\n",
    "    use_amp: bool = True,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        x_norm, m_valid = batch\n",
    "        x_norm = x_norm.to(device, non_blocking=True)\n",
    "        m_valid = m_valid.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            x_recon, _ = model(x_norm)\n",
    "\n",
    "            # boolean mask for indexing\n",
    "            mv = m_valid > 0.5\n",
    "\n",
    "            # if a batch ever has no valid pixels, skip safely\n",
    "            if mv.any():\n",
    "                loss = F.mse_loss(x_recon[mv], x_norm[mv])\n",
    "            else:\n",
    "                loss = torch.zeros((), device=device)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / max(n_batches, 1)\n",
    "\n",
    "def validate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
    "            x_norm, m_valid = batch\n",
    "            x_norm = x_norm.to(device, non_blocking=True)\n",
    "            m_valid = m_valid.to(device, non_blocking=True)\n",
    "\n",
    "            x_recon, _ = model(x_norm)\n",
    "\n",
    "            mv = m_valid > 0.5\n",
    "            if mv.any():\n",
    "                loss = F.mse_loss(x_recon[mv], x_norm[mv])\n",
    "            else:\n",
    "                loss = torch.zeros((), device=device)\n",
    "\n",
    "            total_loss += float(loss.detach().cpu())\n",
    "            n_batches += 1\n",
    "\n",
    "    return total_loss / max(n_batches, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8bf7050",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_gpu_batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astromodal.models.autoencoder import AutoEncoder\n",
    "from torch.amp.GradScaler import GradScaler\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62d6bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(\n",
    "    in_channels = len(bands),\n",
    "    latent_dim = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3bfedf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_loss = train_epoch(model, train_dataset, optimizer, device, \u001b[43mscaler\u001b[49m, USE_AMP)\n",
      "\u001b[31mNameError\u001b[39m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loss = train_epoch(model, train_dataset, optimizer, device, scaler, USE_AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74037f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = validate(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c722f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c798532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
